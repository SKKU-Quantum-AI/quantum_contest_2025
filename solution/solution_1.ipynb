{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac10f685",
   "metadata": {},
   "source": [
    "# 1. Building basic QNN example\n",
    "## 1.a Construct a 2-qubit basic quantum  neural network\n",
    "> 2011.00027 논문을 참고하거나, 자유롭게 FeatureMap과 Ansatz 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89aa2643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit.library import ZZFeatureMap, TwoLocal\n",
    "\n",
    "def FeatureMapBuilder(num_features, reps):\n",
    "    feature_map = ZZFeatureMap(\n",
    "        feature_dimension=num_features,\n",
    "        reps=reps,\n",
    "    )\n",
    "    return feature_map\n",
    "\n",
    "def AnsatzBuilder(num_qubits, reps):\n",
    "    ansatz = TwoLocal(\n",
    "        num_qubits=num_qubits,\n",
    "        rotation_blocks='ry',\n",
    "        entanglement_blocks='cx',\n",
    "        entanglement='full', \n",
    "        reps=reps, \n",
    "        insert_barriers=True\n",
    "    )\n",
    "    return ansatz\n",
    "\n",
    "from qiskit_machine_learning.circuit.library import QNNCircuit\n",
    "\n",
    "def QnnModelCircuitBuilder(num_qubits, reps_feature_map, reps_ansatz):\n",
    "    feature_map = FeatureMapBuilder(num_qubits, reps_feature_map)\n",
    "    ansatz = AnsatzBuilder(num_qubits, reps_ansatz)\n",
    "\n",
    "    qnn_circuit = QNNCircuit(\n",
    "        num_qubits=num_qubits,\n",
    "        feature_map=feature_map,\n",
    "        ansatz=ansatz\n",
    "    )\n",
    "    return qnn_circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df19f78f",
   "metadata": {},
   "source": [
    "- ZZFeatureMap 기반 FeatureMap 생성 함수\n",
    "- TwoLocal 회로 기반 Ansatz 생성 함수\n",
    "- QNN circuit 생성 함수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39864497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1123.41x200.667 with 1 Axes>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qnn_circuit = QnnModelCircuitBuilder(\n",
    "    num_qubits=2,\n",
    "    reps_feature_map=1,\n",
    "    reps_ansatz=1\n",
    ")\n",
    "\n",
    "qnn_circuit.decompose().draw(\"mpl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd64d70c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10bc0f39",
   "metadata": {},
   "source": [
    "## 1.b. Compute Effective Dimension of the Model\n",
    "> Training data의 Distribution에 대한 dependence를 찾기\n",
    "- by varying the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94b26233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.primitives import StatevectorSampler as Sampler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from qiskit_machine_learning.optimizers import COBYLA\n",
    "from qiskit_machine_learning.utils import algorithm_globals\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
    "from qiskit_machine_learning.neural_networks import EffectiveDimension, LocalEffectiveDimension\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2c14e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ParameterVectorElement(θ[0]),\n",
       " ParameterVectorElement(θ[1]),\n",
       " ParameterVectorElement(θ[2]),\n",
       " ParameterVectorElement(θ[3])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler = Sampler()\n",
    "#Sampler 기반 QNN인 samplerQNN 정의\n",
    "qnn = SamplerQNN(\n",
    "    circuit=qnn_circuit,\n",
    "    input_params=qnn_circuit.feature_map.parameters,\n",
    "    weight_params=qnn_circuit.ansatz.parameters,\n",
    "    sampler=sampler,\n",
    ")\n",
    "\n",
    "qnn.input_params\n",
    "qnn.weight_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaf600c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [5000, 8000, 10000, 40000, 60000, 100000, 150000, 200000, 500000, 1000000]\n",
    "def plot_effective_dimension(effective_dimension):\n",
    "    global_ed = effective_dimension\n",
    "\n",
    "    global_eff_dim_0 = global_ed.get_effective_dimension(dataset_size=n[0])\n",
    "\n",
    "    d = qnn.num_weights\n",
    "    \n",
    "    print(\"Data size: {}, global effective dimension: {:.4f}\".format(n[0], global_eff_dim_0))\n",
    "    print(\n",
    "        \"Number of weights: {}, normalized effective dimension: {:.4f}\".format(d, global_eff_dim_0 / d)\n",
    "    )\n",
    "\n",
    "    # global_eff_dim_1 = global_ed.get_effective_dimension(dataset_size=n)\n",
    "    # print(\"Effective dimension: {}\".format(global_eff_dim_1))\n",
    "\n",
    "    # print(\"Number of weights: {}\".format(d))\n",
    "    # plt.plot(n, np.array(global_eff_dim_1) / d)\n",
    "    # plt.xlabel(\"Number of data\")\n",
    "    # plt.ylabel(\"Normalized GLOBAL effective dimension\")\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2da3bfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: Monte Carlo Sampling\n",
      "Finisehd: Monte Carlo Sampling\n",
      "Starting: Fisher Information\n",
      "model_outputs에 0이 없음\n",
      "Finished: Fisher Information\n",
      "Starting: Normalize\n",
      "Finished: Normalize\n",
      "Starting: Effective Dimension\n",
      "Finished: Effective Dimension\n",
      "Data size: 5000, global effective dimension: 3.9435\n",
      "Number of weights: 4, normalized effective dimension: 0.9859\n"
     ]
    }
   ],
   "source": [
    "input_samples = algorithm_globals.random.normal(0, 1, size=(10, qnn.num_inputs))\n",
    "weight_samples = algorithm_globals.random.uniform(0, 1, size=(10, qnn.num_weights))\n",
    "\n",
    "# print(input_samples)\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# tmp_input_samples = MinMaxScaler().fit_transform(input_samples)\n",
    "# print(tmp_input_samples)\n",
    "\n",
    "qnn_ed = EffectiveDimension(\n",
    "    qnn=qnn,\n",
    "    weight_samples=weight_samples,\n",
    "    input_samples=input_samples\n",
    "    )\n",
    "plot_effective_dimension(qnn_ed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7102c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "151e33ce",
   "metadata": {},
   "source": [
    "qnn의 output shape은 무조건 1행짜리 행열\n",
    "2큐비트면 4개 확률분포, 3큐비트면 8개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ff63429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from qiskit_machine_learning.neural_networks import NeuralNetwork\n",
    "# from typing import Tuple, Any, List, Union\n",
    "# import time\n",
    "# import logging\n",
    "# import pandas as pd\n",
    "# from IPython.display import display, Latex\n",
    "# from scipy.special import logsumexp\n",
    "\n",
    "# logger = logging.getLogger(__name__)\n",
    "\n",
    "# class SQuAI_EffectiveDimension:\n",
    "#     def __init__(\n",
    "#             self,\n",
    "#             qnn: NeuralNetwork,\n",
    "#             input_samples: np.ndarray,\n",
    "#             weight_samples: np.ndarray,\n",
    "#             approx_epsilon: float = 1e-10\n",
    "#     ) -> None:\n",
    "#         self._weight_samples = weight_samples\n",
    "#         self._input_samples = input_samples\n",
    "#         self._num_weight_samples = len(self._weight_samples)\n",
    "#         self._num_input_samples = len(self._input_samples)\n",
    "#         self._model = qnn\n",
    "#         self._epsilon = approx_epsilon\n",
    "#         self.fisher_information_matrix: np.ndarray = None\n",
    "#         self.normalized_fisher_information_matrix: np.ndarray = None\n",
    "#         self.effective_dimensions: np.ndarray = None\n",
    "#         self.dataset_sizes = None\n",
    "#         self.gamma = None\n",
    "#         ## For SuperCalculation\n",
    "#         self._compressed_weight_samples:np.ndarray = np.empty((0, self._model.num_weights))\n",
    "#         self._num_compressed_weight_samples:int = 0\n",
    "    \n",
    "#     def run_monte_carlo(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "#         # 가중치 마다의 (num_weights) gradient를 구해야하기에 3차원 배\n",
    "#         grads: Any = np.zeros(\n",
    "#             (\n",
    "#                 self._num_input_samples * self._num_weight_samples,\n",
    "#                 self._model.output_shape[0],\n",
    "#                 self._model.num_weights,\n",
    "#             )\n",
    "#         )\n",
    "#         # 입력 샘플 수 * 가중치 샘플 수 만큼의 조합 만큼의 행\n",
    "#         # output_shape 즉, 3큐비트면 8개의 \n",
    "#         outputs: Any = np.zeros(\n",
    "#             (\n",
    "#                 self._num_input_samples * self._num_weight_samples,\n",
    "#                 self._model.output_shape[0]\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "#         # enumerate 함수 사용해서, index를 붙여가면서 가중치 조합 (세타1, 세타2, ...세타 n)을 사용할 수 있음 \n",
    "#         for i, param_set in enumerate(self._weight_samples):\n",
    "#             t_before_forward = time.time()\n",
    "#             forward_pass = np.asarray(\n",
    "#                 self._model.forward(input_data=self._input_samples, weights=param_set)\n",
    "#             )\n",
    "#             t_after_forward = time.time()\n",
    "\n",
    "#             backward_pass = np.asarray(\n",
    "#                 self._model.backward(input_data=self._input_samples, weights=param_set)[1]\n",
    "#             )\n",
    "#             t_after_backward = time.time()\n",
    "\n",
    "#             t_forward = t_after_forward - t_before_forward\n",
    "#             t_backward = t_after_backward - t_after_forward\n",
    "\n",
    "#             # forward, backward 시간 분석 -> 병목 확인 \n",
    "#             logger.debug(\n",
    "#                 \"Weight sample: %d, forward time: %.3f (s), backward time: %.3f (s)\",\n",
    "#                 i,\n",
    "#                 t_forward,\n",
    "#                 t_backward,\n",
    "#             )\n",
    "\n",
    "#             grads[self._num_input_samples * i : self._num_input_samples * (i + 1)] = backward_pass\n",
    "#             outputs[self._num_input_samples * i : self._num_input_samples * (i + 1)] = forward_pass\n",
    "\n",
    "#         return grads, outputs\n",
    "\n",
    "#     def buildFIM(\n",
    "#             self,\n",
    "#     ) -> np.ndarray:\n",
    "#         gradients, model_outputs = self.run_monte_carlo()\n",
    "        \n",
    "#         if model_outputs.ndim < gradients.ndim:\n",
    "#             model_outputs = np.expand_dims(model_outputs, axis=2)\n",
    "\n",
    "#         mask = model_outputs == 0\n",
    "#         mask_squeezed = np.squeeze(mask)\n",
    "#         if np.any(mask_squeezed):\n",
    "#             rows, cols = np.where(mask_squeezed)\n",
    "#             model_outputs = model_outputs + (mask * self._epsilon)\n",
    "        \n",
    "#         gradvectors = np.sqrt(model_outputs) * gradients / model_outputs\n",
    "\n",
    "#         fisher_information = np.einsum(\"ijk,lji->ikl\", gradvectors, gradvectors.T)\n",
    "\n",
    "#         self.fisher_information_matrix = fisher_information\n",
    "            \n",
    "#         # if (normalization == False):\n",
    "#             # return fisher_information\n",
    "#         # else:\n",
    "#         fisher_trace = np.trace(np.average(fisher_information, axis = 0))\n",
    "\n",
    "        \n",
    "#         fisher_avg = np.average(\n",
    "#             np.reshape(\n",
    "#                 fisher_information,\n",
    "#                 (\n",
    "#                     self._num_weight_samples,\n",
    "#                     self._num_input_samples,\n",
    "#                     self._model.num_weights,\n",
    "#                     self._model.num_weights,\n",
    "#                 ),\n",
    "#             ),\n",
    "#             axis=1,\n",
    "#         )\n",
    "        \n",
    "#         normalized_fisher = self._model.num_weights * fisher_avg / fisher_trace\n",
    "#         # print(normalized_fisher.shape)\n",
    "#         self.normalized_fisher_information_matrix = normalized_fisher\n",
    "#         # return normalized_fisher\n",
    "    \n",
    "#     def printFIM(\n",
    "#             self,\n",
    "#             normalized: bool = True\n",
    "#             ) -> None:\n",
    "#         if (normalized): fim = self.normalized_fisher_information_matrix\n",
    "#         else : self.fisher_information_matrix\n",
    "\n",
    "#         # fim_avg = np.mean(fim, axis=-1) if fim.ndim == 3 else fim\n",
    "\n",
    "#         np.set_printoptions(precision=4, suppress=True)\n",
    "#         print(\"Fisher Information Matrix:\")\n",
    "#         print(fim)\n",
    "\n",
    "#         # 또는 pandas DataFrame으로 보기\n",
    "#         # display(pd.DataFrame(fim))\n",
    "\n",
    "#     # def display_fim_latex(\n",
    "#     #         fim: np.ndarray,\n",
    "#     #         precision: int = 4\n",
    "#     #         ) -> None:\n",
    "#     #     num_matrices = fim.shape[2] if fim.ndim == 3 else 1\n",
    "#     #     fim_list = [fim[:, :, i] for i in range(num_matrices)] if fim.ndim == 3 else [fim]\n",
    "\n",
    "#     #     for idx, matrix in enumerate(fim_list):\n",
    "#     #         # Format each element\n",
    "#     #         latex_rows = []\n",
    "#     #         for row in matrix:\n",
    "#     #             latex_row = \" & \".join([f\"{elem:.{precision}f}\" for elem in row])\n",
    "#     #             latex_rows.append(latex_row)\n",
    "#     #         latex_matrix = \"\\\\\\\\\\n\".join(latex_rows)\n",
    "\n",
    "#     #         # Wrap in LaTeX matrix syntax\n",
    "#     #         latex_code = (\n",
    "#     #             f\"\\\\textbf{{Fisher Information Matrix \\\\#{idx}}} \\\\\\\\\\n\"\n",
    "#     #             \"\\\\[\\n\"\n",
    "#     #             \"\\\\begin{bmatrix}\\n\"\n",
    "#     #             f\"{latex_matrix}\\n\"\n",
    "#     #             \"\\\\end{bmatrix}\\n\"\n",
    "#     #             \"\\\\]\\n\"\n",
    "#     #         )\n",
    "#     #         display(Latex(latex_code))\n",
    "\n",
    "#     def display_all_fims_latex(\n",
    "#             self,\n",
    "#             precision: int = 4,\n",
    "#             normalized: bool = True\n",
    "#             ) -> None:\n",
    "        \n",
    "#         if (normalized): fim = self.normalized_fisher_information_matrix\n",
    "#         else : fim = self.fisher_information_matrix\n",
    "        \n",
    "#         num_fims = fim.shape[0]\n",
    "\n",
    "#         for idx in range(num_fims):\n",
    "#             onefim = fim[idx, :, :]\n",
    "\n",
    "#             # 라텍스 행 생성\n",
    "#             latex_rows = []\n",
    "#             for row in onefim:\n",
    "#                 row_str = \" & \".join([f\"{elem:.{precision}f}\" for elem in row])\n",
    "#                 latex_rows.append(row_str)\n",
    "#             latex_matrix = \"\\\\\\\\\\n\".join(latex_rows)\n",
    "\n",
    "#             # LaTeX 코드 구성\n",
    "#             latex_code = (\n",
    "#                 f\"\\\\textbf{{Fisher Information Matrix \\\\#{idx}}} \\\\\\\\\\n\"\n",
    "#                 \"\\\\[\\n\"\n",
    "#                 \"\\\\begin{bmatrix}\\n\"\n",
    "#                 f\"{latex_matrix}\\n\"\n",
    "#                 \"\\\\end{bmatrix}\\n\"\n",
    "#                 \"\\\\]\\n\"\n",
    "#             )\n",
    "\n",
    "#             display(Latex(latex_code))\n",
    "\n",
    "\n",
    "#     def calculateEffectiveDimension(\n",
    "#         self,\n",
    "#         dataset_size: Union[List[int], np.ndarray, int],\n",
    "#         gamma: Union[List[float], np.ndarray, float] = 1,\n",
    "#     ) -> np.ndarray:\n",
    "#         dataset_size = np.atleast_1d(dataset_size).astype(np.float64)\n",
    "#         gamma = np.atleast_1d(gamma).astype(np.float64)\n",
    "#         self.dataset_sizes = dataset_size\n",
    "#         self.gamma = gamma\n",
    "\n",
    "#         fisher = self.normalized_fisher_information_matrix  # (S, D, D)\n",
    "#         assert fisher is not None, \"normalized_fisher_information_matrix is not set\"\n",
    "#         S, D = fisher.shape[0], fisher.shape[1]\n",
    "\n",
    "#         fisher_exp = fisher[np.newaxis, np.newaxis, :, :, :]\n",
    "#         n_exp = dataset_size[:, np.newaxis, np.newaxis, np.newaxis]\n",
    "#         g_exp = gamma[np.newaxis, :, np.newaxis, np.newaxis]\n",
    "\n",
    "#         # scale factor\n",
    "#         with np.errstate(divide='ignore', invalid='ignore'):\n",
    "#             denom_term = np.log(n_exp)\n",
    "#             scale = (n_exp * g_exp) / (2 * np.pi * denom_term)\n",
    "#             scale = np.where(np.isfinite(scale), scale, 0.0)\n",
    "\n",
    "#         scale = scale[:, :, np.newaxis, :, :]\n",
    "#         f_mod = fisher_exp * scale\n",
    "#         I = np.eye(D)[np.newaxis, np.newaxis, np.newaxis, :, :]\n",
    "#         one_plus_fmod = I + f_mod\n",
    "\n",
    "#         # logdet with safe handling\n",
    "#         sign, logdet = np.linalg.slogdet(one_plus_fmod)\n",
    "#         # Optional: mask very large/invalid logdets\n",
    "#         logdet = np.where(np.isfinite(logdet), logdet, np.nan)  # or 0.0\n",
    "#         dets_div = logdet / 2\n",
    "\n",
    "#         logsum = logsumexp(dets_div, axis=2, b=np.isfinite(dets_div).astype(float))\n",
    "#         denom = np.log(dataset_size / (2 * np.pi * np.log(dataset_size)))\n",
    "#         denom = np.where(np.isfinite(denom), denom, np.nan)[:, np.newaxis]\n",
    "\n",
    "#         effective_dims = 2 * (logsum - np.log(S)) / denom\n",
    "#         self.effective_dimensions = effective_dims\n",
    "\n",
    "#         return effective_dims\n",
    "    \n",
    "        \n",
    "#     def display_effective_dim_latex_table(\n",
    "#             self,\n",
    "#             precision: int = 4\n",
    "#     ):\n",
    "#         \"\"\"\n",
    "#         Display effective dimension result as a LaTeX table.\n",
    "\n",
    "#         Args:\n",
    "#             effective_dims: 2D array of shape (len(dataset_sizes), len(gammas))\n",
    "#             dataset_sizes: list or array of dataset sizes (rows)\n",
    "#             gammas: list or array of gamma values (columns)\n",
    "#             precision: number of decimal places for table values\n",
    "#         \"\"\"\n",
    "#         dataset_sizes = np.atleast_1d(self.dataset_sizes)\n",
    "#         gammas = np.atleast_1d(self.gamma)\n",
    "\n",
    "#         # assert effective_dims.shape == (len(dataset_sizes), len(gammas)), \"Shape mismatch!\"\n",
    "\n",
    "#         # 헤더 구성\n",
    "#         col_headers = \" & \" + \" & \".join([f\"\\\\gamma={g}\" for g in gammas]) + \" \\\\\\\\\"\n",
    "#         latex_rows = [col_headers]\n",
    "\n",
    "#         # 나머지 행\n",
    "#         for i, n in enumerate(dataset_sizes):\n",
    "#             row_values = \" & \".join([f\"{val:.{precision}f}\" for val in self.effective_dimensions[i]])\n",
    "#             row = f\"n={n} & {row_values} \\\\\\\\\"\n",
    "#             latex_rows.append(row)\n",
    "\n",
    "#         latex_body = \"\\n\".join(latex_rows)\n",
    "\n",
    "#         latex_code = (\n",
    "#             \"\\\\[\\n\"\n",
    "#             \"\\\\begin{array}{\" + \"c\" * (len(gammas) + 1) + \"}\\n\"\n",
    "#             f\"{latex_body}\\n\"\n",
    "#             \"\\\\end{array}\\n\"\n",
    "#             \"\\\\]\"\n",
    "#         )\n",
    "\n",
    "#         display(Latex(latex_code))\n",
    "\n",
    "\n",
    "\n",
    "#     # 최대 LED 가지는 sample 하나를 반환 \n",
    "#     def maximum_local_effective_dimension_sample(\n",
    "#             self,\n",
    "#             target_weight_sample: np.ndarray\n",
    "#     ):\n",
    "#         local_effective_dimensions = []\n",
    "#         for weight_sample in target_weight_sample:\n",
    "#             # print(f\"weight_sample {weight_sample}\")\n",
    "#             weight_sample = np.asarray(weight_sample).reshape(1, -1)\n",
    "#             self._weight_samples = weight_sample\n",
    "#             self._num_weight_samples = len(weight_sample)\n",
    "#             self.buildFIM()\n",
    "#             local_effective_dimensions.append(self.calculateEffectiveDimension(dataset_size=100000, gamma=0.5))\n",
    "\n",
    "#         maximum_led = max(local_effective_dimensions)\n",
    "#         max_idx = local_effective_dimensions.index(maximum_led)\n",
    "#         return target_weight_sample[max_idx]\n",
    "\n",
    "#     # Sample을 받고, 그 Sample 각 weight 값에 대해 상한, 하한 값을 만들어 반환 \n",
    "#     def weight_value_constrainer(\n",
    "#             self,\n",
    "#             target_sample: np.ndarray,\n",
    "#             shrink: float,\n",
    "#     ) -> List[Tuple[float, float]]:\n",
    "#         half = shrink / 2\n",
    "\n",
    "#         bounds = []\n",
    "#         for val in target_sample:\n",
    "#             lower = max(0.0, val - half)\n",
    "#             upper = min(1.0, val + half)\n",
    "#             bounds.append((upper, lower))\n",
    "\n",
    "#         return bounds\n",
    "\n",
    "#     def generate_local_weight_samples(\n",
    "#             self,\n",
    "#             bounds: List[Tuple[float, float]],\n",
    "#             num_new_sample: int\n",
    "#     ) -> np.ndarray:\n",
    "#         print(\"Generating local weight samples\")\n",
    "#         upper = np.array([b[0] for b in bounds])\n",
    "#         lower = np.array([b[1] for b in bounds])\n",
    "        \n",
    "#         new_weight_sample = algorithm_globals.random.uniform(\n",
    "#             low=lower,\n",
    "#             high=upper,\n",
    "#             size=(num_new_sample, self._model.num_weights)\n",
    "#         )\n",
    "#         self._compressed_weight_samples = np.concatenate([self._compressed_weight_samples, new_weight_sample], axis=0)\n",
    "#         print(f\"### Newly generated samples: {new_weight_sample}\")\n",
    "#         print(f\"### Number of new generated samples: {len(new_weight_sample)}\")\n",
    "#         # print(f\"### Tracking compress weight samples: {self._compressed_weight_samples}\")\n",
    "#         self._num_compressed_weight_samples += len(new_weight_sample)\n",
    "#         return new_weight_sample\n",
    "\n",
    "#     def compress_weight_samples(\n",
    "#             self,\n",
    "#     ) -> np.ndarray:\n",
    "#         print(\"### Compressing weight samples\")\n",
    "#         num_each_weight_samples = self._num_weight_samples\n",
    "#         new_boundary_factor = self._num_weight_samples \n",
    "#         # 처음 입력이 들어왔을 때는, 0과 1 사이의 값에서 random 하게 N^{1/파라미터 수} 만큼 뽑기 -> 그냥 무작위로 줄이기\n",
    "#         bound = [(1, 0)]\n",
    "#         # print(f\"original N{N}\")\n",
    "#         while True:\n",
    "#             num_each_weight_samples = int(num_each_weight_samples ** (1 / self._model.num_weights)) # 차원 만큼의 제곱근 한 것 만큼의 Sample로 대표 추정 \n",
    "            \n",
    "#             new_weight_sample = self.generate_local_weight_samples(bounds = bound, num_new_sample = num_each_weight_samples)\n",
    "#             # 새로운 weight 들 중 LED 최대값을 가지는 Sample\n",
    "#             max_sample = self.maximum_local_effective_dimension_sample(new_weight_sample)\n",
    "            \n",
    "#             new_boundary_factor = new_boundary_factor ** (1 / self._model.num_weights)\n",
    "#             # upper, lower 값, 새로운 sample들 중 최대 LED 만드는 sample로 uppper, lower update\n",
    "#             bound = self.weight_value_constrainer(target_sample=max_sample, shrink = new_boundary_factor)\n",
    "#             if num_each_weight_samples == 1:\n",
    "#                 self.generate_local_weight_samples(bounds = bound, num_new_sample = num_each_weight_samples)\n",
    "#                 break\n",
    "\n",
    "#     def super_calculate_effective_dimension(\n",
    "#             self,\n",
    "#             dataset_size: Union[List[int], np.ndarray, int],\n",
    "#             gamma: Union[List[float], np.ndarray, float] = 1,\n",
    "#     ) -> np.ndarray:\n",
    "#         self.compress_weight_samples()\n",
    "#         self._weight_samples = self.compress_weight_samples\n",
    "#         self._num_weight_samples = self._num_compressed_weight_samples\n",
    "#         self.calculateEffectiveDimension(dataset_size=dataset_size, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85ab1929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: Monte Carlo Sampling\n",
      "Finisehd: Monte Carlo Sampling\n",
      "Starting: Fisher Information\n",
      "model_outputs == 0인 인덱스:\n",
      " - 위치 [42, 2]:\n",
      "   → gradient = [ 0.00097656 -0.00097656  0.01416016 -0.01806641]\n",
      "Finished: Fisher Information\n",
      "Starting: Normalize\n",
      "Finished: Normalize\n",
      "Starting: Effective Dimension\n",
      "Finished: Effective Dimension\n",
      "Data size: 5000, global effective dimension: 0.8611\n",
      "Number of weights: 4, normalized effective dimension: 0.2153\n"
     ]
    }
   ],
   "source": [
    "input_samples = algorithm_globals.random.normal(0, 1, size=(10, qnn.num_inputs))\n",
    "weight_samples = algorithm_globals.random.uniform(0, 1, size=(10, qnn.num_weights))\n",
    "\n",
    "# print(input_samples)\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# tmp_input_samples = MinMaxScaler().fit_transform(input_samples)\n",
    "# print(tmp_input_samples)\n",
    "\n",
    "qnn_ed = EffectiveDimension(\n",
    "    qnn=qnn,\n",
    "    weight_samples=weight_samples,\n",
    "    input_samples=input_samples\n",
    "    )\n",
    "plot_effective_dimension(qnn_ed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2103d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_effective_dimension(effective_dimension):\n",
    "    global_ed = effective_dimension\n",
    "\n",
    "    global_eff_dim_0 = global_ed.get_effective_dimension(dataset_size=n[0])\n",
    "\n",
    "    d = qnn.num_weights\n",
    "    \n",
    "    print(\"Data size: {}, global effective dimension: {:.4f}\".format(n[0], global_eff_dim_0))\n",
    "    print(\n",
    "        \"Number of weights: {}, normalized effective dimension: {:.4f}\".format(d, global_eff_dim_0 / d)\n",
    "    )\n",
    "\n",
    "    # global_eff_dim_1 = global_ed.get_effective_dimension(dataset_size=n)\n",
    "    # print(\"Effective dimension: {}\".format(global_eff_dim_1))\n",
    "\n",
    "    # print(\"Number of weights: {}\".format(d))\n",
    "    # plt.plot(n, np.array(global_eff_dim_1) / d)\n",
    "    # plt.xlabel(\"Number of data\")\n",
    "    # plt.ylabel(\"Normalized GLOBAL effective dimension\")\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa2e65f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3500518 , 0.95516767, 0.68931489, 0.92591532],\n",
       "       [0.04064645, 0.29054348, 0.79570884, 0.68317849],\n",
       "       [0.53619889, 0.87272715, 0.90127789, 0.36431388],\n",
       "       [0.55713429, 0.77889123, 0.92059393, 0.9966184 ],\n",
       "       [0.66222495, 0.7172724 , 0.65114481, 0.73872335],\n",
       "       [0.48811579, 0.6396639 , 0.08457492, 0.54364345],\n",
       "       [0.43336367, 0.58555597, 0.60586143, 0.0117928 ],\n",
       "       [0.78767596, 0.52880616, 0.73771065, 0.01065026],\n",
       "       [0.27000529, 0.93296628, 0.73885756, 0.28516157],\n",
       "       [0.88214601, 0.99232991, 0.38023007, 0.25125895]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input_samples = algorithm_globals.random.normal(0, 1, size=(10, qnn.num_inputs))\n",
    "weight_samples = algorithm_globals.random.uniform(0, 1, size=(10, qnn.num_weights))\n",
    "weight_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d313e481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bc7aef4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SQuAI_EffectiveDimension' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m input_samples = algorithm_globals.random.normal(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, size=(num_samples, qnn.num_inputs))\n\u001b[32m      3\u001b[39m weight_samples = algorithm_globals.random.uniform(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, size=(num_samples, qnn.num_weights))\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m effective_dimension = \u001b[43mSQuAI_EffectiveDimension\u001b[49m(\n\u001b[32m      6\u001b[39m     qnn=qnn,\n\u001b[32m      7\u001b[39m     weight_samples=weight_samples,\n\u001b[32m      8\u001b[39m     input_samples=input_samples,\n\u001b[32m      9\u001b[39m )\n\u001b[32m     10\u001b[39m effective_dimension.buildFIM()\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# effective_dimension.printFIM()\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'SQuAI_EffectiveDimension' is not defined"
     ]
    }
   ],
   "source": [
    "num_samples = 100\n",
    "input_samples = algorithm_globals.random.normal(0, 1, size=(num_samples, qnn.num_inputs))\n",
    "weight_samples = algorithm_globals.random.uniform(0, 1, size=(num_samples, qnn.num_weights))\n",
    "\n",
    "effective_dimension = SQuAI_EffectiveDimension(\n",
    "    qnn=qnn,\n",
    "    weight_samples=weight_samples,\n",
    "    input_samples=input_samples,\n",
    ")\n",
    "effective_dimension.buildFIM()\n",
    "# effective_dimension.printFIM()\n",
    "print(effective_dimension.fisher_information_matrix.shape)\n",
    "# effective_dimension.display_all_fims_latex(precision=4)\n",
    "# effective_dimension.printFIM()\n",
    "\n",
    "n = [5000, 8000, 10000, 40000, 60000, 100000, 150000, 200000, 500000, 1000000]\n",
    "gamma = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "effective_dimension.calculateEffectiveDimension(dataset_size=n, gamma=gamma)\n",
    "effective_dimension.display_effective_dim_latex_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1565135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Compressing weight samples\n",
      "Generating local weight samples\n",
      "### Newly generated samples: [[0.3318 0.853  0.1344 0.6027]\n",
      " [0.0693 0.0912 0.8231 0.8262]]\n",
      "### Number of new generated samples: 2\n",
      "Generating local weight samples\n",
      "### Newly generated samples: [[0.4154 0.2458 0.1956 0.348 ]]\n",
      "### Number of new generated samples: 1\n",
      "Generating local weight samples\n",
      "### Newly generated samples: [[0.4755 0.5581 0.0118 0.5766]]\n",
      "### Number of new generated samples: 1\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\[\n",
       "\\begin{array}{cc}\n",
       " & \\gamma=1.0 \\\\\n",
       "n=5000.0 & 4.0018 \\\\\n",
       "n=8000.0 & 3.9986 \\\\\n",
       "n=10000.0 & 3.9977 \\\\\n",
       "n=40000.0 & 3.9955 \\\\\n",
       "n=60000.0 & 3.9955 \\\\\n",
       "n=100000.0 & 3.9955 \\\\\n",
       "n=150000.0 & 3.9956 \\\\\n",
       "n=200000.0 & 3.9957 \\\\\n",
       "n=500000.0 & 3.9960 \\\\\n",
       "n=1000000.0 & 3.9963 \\\\\n",
       "\\end{array}\n",
       "\\]"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_samples = 30\n",
    "\n",
    "input_samples = algorithm_globals.random.normal(0, 1, size=(30, qnn.num_inputs))\n",
    "weight_samples = algorithm_globals.random.uniform(0, 1, size=(num_samples, qnn.num_weights))\n",
    "\n",
    "effective_dimension = SQuAI_EffectiveDimension(\n",
    "    qnn=qnn,\n",
    "    weight_samples=weight_samples,\n",
    "    input_samples=input_samples,\n",
    ")\n",
    "effective_dimension.super_calculate_effective_dimension(dataset_size=n)\n",
    "\n",
    "effective_dimension.display_effective_dim_latex_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bcb40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "effective_dimension_10000 = effective_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fbd134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\[\n",
       "\\begin{array}{cc}\n",
       " & \\gamma=1.0 \\\\\n",
       "n=5000.0 & 3.7905 \\\\\n",
       "n=8000.0 & 3.8036 \\\\\n",
       "n=10000.0 & 3.8096 \\\\\n",
       "n=40000.0 & 3.8427 \\\\\n",
       "n=60000.0 & 3.8508 \\\\\n",
       "n=100000.0 & 3.8600 \\\\\n",
       "n=150000.0 & 3.8667 \\\\\n",
       "n=200000.0 & 3.8711 \\\\\n",
       "n=500000.0 & 3.8834 \\\\\n",
       "n=1000000.0 & 3.8914 \\\\\n",
       "\\end{array}\n",
       "\\]"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8049, 0.3781, 0.6844, 0.4946],\n",
       "       [0.7009, 0.4669, 0.052 , 0.847 ],\n",
       "       [0.506 , 0.6953, 0.3788, 0.7132],\n",
       "       [0.6946, 0.9108, 0.4777, 0.5048],\n",
       "       [0.3852, 0.1883, 0.3517, 0.636 ],\n",
       "       [0.265 , 0.0616, 0.4212, 0.0112],\n",
       "       [0.1067, 0.415 , 0.5149, 0.2116],\n",
       "       [0.684 , 0.4589, 0.1056, 0.1458],\n",
       "       [0.1899, 0.3022, 0.5199, 0.5855],\n",
       "       [0.0552, 0.6844, 0.2701, 0.8   ],\n",
       "       [0.4407, 0.7736, 0.5079, 0.3631],\n",
       "       [0.9776, 0.3964, 0.7212, 0.8117]])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effective_dimension_10000.display_effective_dim_latex_table()\n",
    "effective_dimension_10000._compressed_weight_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a9f681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############\n",
      "weight: [0.0954 0.567  0.8617 0.6652]\n",
      "weight: [0.2938 0.0488 0.3834 0.4056]\n",
      "weight: [0.1912 0.7218 0.4875 0.4508]\n",
      "weight: [0.7732 0.7185 0.5278 0.4566]\n",
      "weight: [0.933  0.9096 0.8544 0.5276]\n",
      "weight: [0.2511 0.7069 0.3749 0.4889]\n",
      "weight: [0.7341 0.0807 0.2149 0.3145]\n",
      "compressed_weight_num: 7\n"
     ]
    }
   ],
   "source": [
    "# for weight in weight_samples:\n",
    "    # print(f\"weight: {weight}\")\n",
    "\n",
    "print(\"#############\")\n",
    "for weight in effective_dimension._compressed_weight_samples:\n",
    "    print(f\"weight: {weight}\")\n",
    "\n",
    "print(f\"compressed_weight_num: {effective_dimension._num_compressed_weight_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826945ff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f12e4de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_machine_learning.neural_networks import NeuralNetwork\n",
    "from typing import Tuple, Any, List, Union\n",
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "from IPython.display import display, Latex\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class SQuAI_EffectiveDimension:\n",
    "    def __init__(\n",
    "            self,\n",
    "            qnn: NeuralNetwork,\n",
    "            input_samples: np.ndarray,\n",
    "            weight_samples: np.ndarray,\n",
    "            approx_epsilon: float = 1e-10\n",
    "    ) -> None:\n",
    "        self._weight_samples = weight_samples\n",
    "        self._input_samples = input_samples\n",
    "        self._num_weight_samples = len(self._weight_samples)\n",
    "        self._num_input_samples = len(self._input_samples)\n",
    "        self._model = qnn\n",
    "        self._epsilon = approx_epsilon\n",
    "        self.fisher_information_matrix: np.ndarray = None\n",
    "        self.normalized_fisher_information_matrix: np.ndarray = None\n",
    "        self.effective_dimensions: np.ndarray = None\n",
    "        self.dataset_sizes = None\n",
    "        self.gamma = None\n",
    "        ## For SuperCalculation\n",
    "        self._compressed_weight_samples:np.ndarray = np.empty((0, self._model.num_weights))\n",
    "        self._num_compressed_weight_samples:int = 0\n",
    "    \n",
    "    def run_monte_carlo(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        # 가중치 마다의 (num_weights) gradient를 구해야하기에 3차원 배\n",
    "        grads: Any = np.zeros(\n",
    "            (\n",
    "                self._num_input_samples * self._num_weight_samples,\n",
    "                self._model.output_shape[0],\n",
    "                self._model.num_weights,\n",
    "            )\n",
    "        )\n",
    "        # 입력 샘플 수 * 가중치 샘플 수 만큼의 조합 만큼의 행\n",
    "        # output_shape 즉, 3큐비트면 8개의 \n",
    "        outputs: Any = np.zeros(\n",
    "            (\n",
    "                self._num_input_samples * self._num_weight_samples,\n",
    "                self._model.output_shape[0]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # enumerate 함수 사용해서, index를 붙여가면서 가중치 조합 (세타1, 세타2, ...세타 n)을 사용할 수 있음 \n",
    "        for i, param_set in enumerate(self._weight_samples):\n",
    "            t_before_forward = time.time()\n",
    "            forward_pass = np.asarray(\n",
    "                self._model.forward(input_data=self._input_samples, weights=param_set)\n",
    "            )\n",
    "            t_after_forward = time.time()\n",
    "\n",
    "            backward_pass = np.asarray(\n",
    "                self._model.backward(input_data=self._input_samples, weights=param_set)[1]\n",
    "            )\n",
    "            t_after_backward = time.time()\n",
    "\n",
    "            t_forward = t_after_forward - t_before_forward\n",
    "            t_backward = t_after_backward - t_after_forward\n",
    "\n",
    "            # forward, backward 시간 분석 -> 병목 확인 \n",
    "            logger.debug(\n",
    "                \"Weight sample: %d, forward time: %.3f (s), backward time: %.3f (s)\",\n",
    "                i,\n",
    "                t_forward,\n",
    "                t_backward,\n",
    "            )\n",
    "\n",
    "            grads[self._num_input_samples * i : self._num_input_samples * (i + 1)] = backward_pass\n",
    "            outputs[self._num_input_samples * i : self._num_input_samples * (i + 1)] = forward_pass\n",
    "\n",
    "        return grads, outputs\n",
    "\n",
    "    def buildFIM(\n",
    "            self,\n",
    "    ) -> np.ndarray:\n",
    "        gradients, model_outputs = self.run_monte_carlo()\n",
    "        \n",
    "        if model_outputs.ndim < gradients.ndim:\n",
    "            model_outputs = np.expand_dims(model_outputs, axis=2)\n",
    "\n",
    "        mask = model_outputs == 0\n",
    "        mask_squeezed = np.squeeze(mask)\n",
    "        if np.any(mask_squeezed):\n",
    "            rows, cols = np.where(mask_squeezed)\n",
    "            model_outputs = model_outputs + (mask * self._epsilon)\n",
    "        \n",
    "        gradvectors = np.sqrt(model_outputs) * gradients / model_outputs\n",
    "\n",
    "        fisher_information = np.einsum(\"ijk,lji->ikl\", gradvectors, gradvectors.T)\n",
    "\n",
    "        self.fisher_information_matrix = fisher_information\n",
    "            \n",
    "        # if (normalization == False):\n",
    "            # return fisher_information\n",
    "        # else:\n",
    "        fisher_trace = np.trace(np.average(fisher_information, axis = 0))\n",
    "\n",
    "        \n",
    "        fisher_avg = np.average(\n",
    "            np.reshape(\n",
    "                fisher_information,\n",
    "                (\n",
    "                    self._num_weight_samples,\n",
    "                    self._num_input_samples,\n",
    "                    self._model.num_weights,\n",
    "                    self._model.num_weights,\n",
    "                ),\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "        \n",
    "        normalized_fisher = self._model.num_weights * fisher_avg / fisher_trace\n",
    "        # print(normalized_fisher.shape)\n",
    "        self.normalized_fisher_information_matrix = normalized_fisher\n",
    "        # return normalized_fisher\n",
    "    \n",
    "    def printFIM(\n",
    "            self,\n",
    "            normalized: bool = True\n",
    "            ) -> None:\n",
    "        if (normalized): fim = self.normalized_fisher_information_matrix\n",
    "        else : self.fisher_information_matrix\n",
    "\n",
    "        # fim_avg = np.mean(fim, axis=-1) if fim.ndim == 3 else fim\n",
    "\n",
    "        np.set_printoptions(precision=4, suppress=True)\n",
    "        print(\"Fisher Information Matrix:\")\n",
    "        print(fim)\n",
    "\n",
    "        # 또는 pandas DataFrame으로 보기\n",
    "        # display(pd.DataFrame(fim))\n",
    "\n",
    "    # def display_fim_latex(\n",
    "    #         fim: np.ndarray,\n",
    "    #         precision: int = 4\n",
    "    #         ) -> None:\n",
    "    #     num_matrices = fim.shape[2] if fim.ndim == 3 else 1\n",
    "    #     fim_list = [fim[:, :, i] for i in range(num_matrices)] if fim.ndim == 3 else [fim]\n",
    "\n",
    "    #     for idx, matrix in enumerate(fim_list):\n",
    "    #         # Format each element\n",
    "    #         latex_rows = []\n",
    "    #         for row in matrix:\n",
    "    #             latex_row = \" & \".join([f\"{elem:.{precision}f}\" for elem in row])\n",
    "    #             latex_rows.append(latex_row)\n",
    "    #         latex_matrix = \"\\\\\\\\\\n\".join(latex_rows)\n",
    "\n",
    "    #         # Wrap in LaTeX matrix syntax\n",
    "    #         latex_code = (\n",
    "    #             f\"\\\\textbf{{Fisher Information Matrix \\\\#{idx}}} \\\\\\\\\\n\"\n",
    "    #             \"\\\\[\\n\"\n",
    "    #             \"\\\\begin{bmatrix}\\n\"\n",
    "    #             f\"{latex_matrix}\\n\"\n",
    "    #             \"\\\\end{bmatrix}\\n\"\n",
    "    #             \"\\\\]\\n\"\n",
    "    #         )\n",
    "    #         display(Latex(latex_code))\n",
    "\n",
    "    def display_all_fims_latex(\n",
    "            self,\n",
    "            precision: int = 4,\n",
    "            normalized: bool = True\n",
    "            ) -> None:\n",
    "        \n",
    "        if (normalized): fim = self.normalized_fisher_information_matrix\n",
    "        else : fim = self.fisher_information_matrix\n",
    "        \n",
    "        num_fims = fim.shape[0]\n",
    "\n",
    "        for idx in range(num_fims):\n",
    "            onefim = fim[idx, :, :]\n",
    "\n",
    "            # 라텍스 행 생성\n",
    "            latex_rows = []\n",
    "            for row in onefim:\n",
    "                row_str = \" & \".join([f\"{elem:.{precision}f}\" for elem in row])\n",
    "                latex_rows.append(row_str)\n",
    "            latex_matrix = \"\\\\\\\\\\n\".join(latex_rows)\n",
    "\n",
    "            # LaTeX 코드 구성\n",
    "            latex_code = (\n",
    "                f\"\\\\textbf{{Fisher Information Matrix \\\\#{idx}}} \\\\\\\\\\n\"\n",
    "                \"\\\\[\\n\"\n",
    "                \"\\\\begin{bmatrix}\\n\"\n",
    "                f\"{latex_matrix}\\n\"\n",
    "                \"\\\\end{bmatrix}\\n\"\n",
    "                \"\\\\]\\n\"\n",
    "            )\n",
    "\n",
    "            display(Latex(latex_code))\n",
    "\n",
    "\n",
    "    def calculateEffectiveDimension(\n",
    "        self,\n",
    "        dataset_size: Union[List[int], np.ndarray, int],\n",
    "        gamma: Union[List[float], np.ndarray, float] = 1,\n",
    "    ) -> np.ndarray:\n",
    "        dataset_size = np.atleast_1d(dataset_size).astype(np.float64)\n",
    "        gamma = np.atleast_1d(gamma).astype(np.float64)\n",
    "        self.dataset_sizes = dataset_size\n",
    "        self.gamma = gamma\n",
    "\n",
    "        fisher = self.normalized_fisher_information_matrix  # (S, D, D)\n",
    "        assert fisher is not None, \"normalized_fisher_information_matrix is not set\"\n",
    "        S, D = fisher.shape[0], fisher.shape[1]\n",
    "\n",
    "        fisher_exp = fisher[np.newaxis, np.newaxis, :, :, :]\n",
    "        n_exp = dataset_size[:, np.newaxis, np.newaxis, np.newaxis]\n",
    "        g_exp = gamma[np.newaxis, :, np.newaxis, np.newaxis]\n",
    "\n",
    "        # scale factor\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            denom_term = np.log(n_exp)\n",
    "            scale = (n_exp * g_exp) / (2 * np.pi * denom_term)\n",
    "            scale = np.where(np.isfinite(scale), scale, 0.0)\n",
    "\n",
    "        scale = scale[:, :, np.newaxis, :, :]\n",
    "        f_mod = fisher_exp * scale\n",
    "        I = np.eye(D)[np.newaxis, np.newaxis, np.newaxis, :, :]\n",
    "        one_plus_fmod = I + f_mod\n",
    "\n",
    "        # logdet with safe handling\n",
    "        sign, logdet = np.linalg.slogdet(one_plus_fmod)\n",
    "        # Optional: mask very large/invalid logdets\n",
    "        logdet = np.where(np.isfinite(logdet), logdet, np.nan)  # or 0.0\n",
    "        dets_div = logdet / 2\n",
    "\n",
    "        logsum = logsumexp(dets_div, axis=2, b=np.isfinite(dets_div).astype(float))\n",
    "        denom = np.log(dataset_size / (2 * np.pi * np.log(dataset_size)))\n",
    "        denom = np.where(np.isfinite(denom), denom, np.nan)[:, np.newaxis]\n",
    "\n",
    "        effective_dims = 2 * (logsum - np.log(S)) / denom\n",
    "        effective_dims /= self._model.num_weights\n",
    "        self.effective_dimensions = effective_dims\n",
    "        \n",
    "        return effective_dims\n",
    "    \n",
    "        \n",
    "    def display_effective_dim_latex_table(\n",
    "            self,\n",
    "            precision: int = 4\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Display effective dimension result as a LaTeX table.\n",
    "\n",
    "        Args:\n",
    "            effective_dims: 2D array of shape (len(dataset_sizes), len(gammas))\n",
    "            dataset_sizes: list or array of dataset sizes (rows)\n",
    "            gammas: list or array of gamma values (columns)\n",
    "            precision: number of decimal places for table values\n",
    "        \"\"\"\n",
    "        dataset_sizes = np.atleast_1d(self.dataset_sizes)\n",
    "        gammas = np.atleast_1d(self.gamma)\n",
    "\n",
    "        # assert effective_dims.shape == (len(dataset_sizes), len(gammas)), \"Shape mismatch!\"\n",
    "\n",
    "        # 헤더 구성\n",
    "        col_headers = \" & \" + \" & \".join([f\"\\\\gamma={g}\" for g in gammas]) + \" \\\\\\\\\"\n",
    "        latex_rows = [col_headers]\n",
    "\n",
    "        # 나머지 행\n",
    "        for i, n in enumerate(dataset_sizes):\n",
    "            row_values = \" & \".join([f\"{val:.{precision}f}\" for val in self.effective_dimensions[i]])\n",
    "            row = f\"n={n} & {row_values} \\\\\\\\\"\n",
    "            latex_rows.append(row)\n",
    "\n",
    "        latex_body = \"\\n\".join(latex_rows)\n",
    "\n",
    "        latex_code = (\n",
    "            \"\\\\[\\n\"\n",
    "            \"\\\\begin{array}{\" + \"c\" * (len(gammas) + 1) + \"}\\n\"\n",
    "            f\"{latex_body}\\n\"\n",
    "            \"\\\\end{array}\\n\"\n",
    "            \"\\\\]\"\n",
    "        )\n",
    "\n",
    "        display(Latex(latex_code))\n",
    "\n",
    "    def threshold_local_effective_dimension_samples(\n",
    "            self,\n",
    "            target_weight_sample: np.ndarray,\n",
    "            threshold: float = 0.5,\n",
    "            dataset_size: int = 100000,\n",
    "            gamma: float = 0.5\n",
    "        ) -> np.ndarray:\n",
    "            print(\"### Starting: Threshold down scaling\")\n",
    "            # print(f\"Threshold in the function : {threshold}\")\n",
    "            \"\"\"\n",
    "            LED 값이 threshold 이상인 weight sample들만 반환.\n",
    "            만약 어떤 sample도 threshold 이상이 아니면 최대 LED sample 하나만 반환.\n",
    "            \"\"\"\n",
    "            qualified_samples = []\n",
    "            local_effective_dimensions = []\n",
    "\n",
    "            for weight_sample in target_weight_sample:\n",
    "                weight_sample = np.asarray(weight_sample).reshape(1, -1)\n",
    "                self._weight_samples = weight_sample\n",
    "                self._num_weight_samples = 1\n",
    "                self.buildFIM()\n",
    "\n",
    "                led = self.calculateEffectiveDimension(dataset_size=dataset_size, gamma=gamma)\n",
    "                local_effective_dimensions.append(led)\n",
    "                # print(led[0][0] / self._model.num_weights)\n",
    "                if led[0][0] / self._model.num_weights >= threshold:\n",
    "                    qualified_samples.append(weight_sample)\n",
    "            \n",
    "            print(\"### Ending: Threshold down scaling\")\n",
    "\n",
    "            if qualified_samples:\n",
    "                return np.vstack(qualified_samples)  # shape: (n_passed, weight_dim)\n",
    "            else:\n",
    "                # threshold 이상이 없을 경우 최대값 하나만 반환\n",
    "                max_idx = int(np.argmax(local_effective_dimensions))\n",
    "                return np.asarray(target_weight_sample[max_idx]).reshape(1, -1)\n",
    "        \n",
    "    def maximum_local_effective_dimension_sample(\n",
    "                self,\n",
    "                target_weight_sample: np.ndarray\n",
    "        ):\n",
    "            print(\"### Starting: Maximum LED Sample\")\n",
    "            local_effective_dimensions = []\n",
    "            for weight_sample in target_weight_sample:\n",
    "                # print(f\"weight_sample {weight_sample}\")\n",
    "                weight_sample = np.asarray(weight_sample).reshape(1, -1)\n",
    "                self._weight_samples = weight_sample\n",
    "                self._num_weight_samples = len(weight_sample)\n",
    "                self.buildFIM()\n",
    "                local_effective_dimensions.append(self.calculateEffectiveDimension(dataset_size=100000, gamma=0.5))\n",
    "\n",
    "            maximum_led = max(local_effective_dimensions)\n",
    "            max_idx = local_effective_dimensions.index(maximum_led)\n",
    "            print(\"### Ending: Maximum LED Sample\")\n",
    "            return target_weight_sample[max_idx]\n",
    "\n",
    "\n",
    "        # Sample을 받고, 그 Sample 각 weight 값에 대해 상한, 하한 값을 만들어 반환 \n",
    "    def weight_value_constrainer(\n",
    "                self,\n",
    "                target_sample: np.ndarray,\n",
    "                shrink: float,\n",
    "        ) -> List[Tuple[float, float]]:\n",
    "            half = shrink / 2\n",
    "\n",
    "            bounds = []\n",
    "            for val in target_sample:\n",
    "                lower = max(0.0, val - half)\n",
    "                upper = min(1.0, val + half)\n",
    "                bounds.append((upper, lower))\n",
    "            print(f\"### Bounds {bounds}\")\n",
    "            return bounds\n",
    "\n",
    "    def generate_local_weight_samples(\n",
    "                self,\n",
    "                bounds: List[Tuple[float, float]],\n",
    "                num_new_sample: int\n",
    "        ) -> np.ndarray:\n",
    "            print(\"### Starting: Generating local weight samples\")\n",
    "            upper = np.array([b[0] for b in bounds])\n",
    "            lower = np.array([b[1] for b in bounds])\n",
    "            \n",
    "            new_weight_sample = algorithm_globals.random.uniform(\n",
    "                low=lower,\n",
    "                high=upper,\n",
    "                size=(num_new_sample, self._model.num_weights)\n",
    "            )\n",
    "            self._compressed_weight_samples = np.concatenate([self._compressed_weight_samples, new_weight_sample], axis=0)\n",
    "            # print(f\"### Newly generated samples: {new_weight_sample}\")\n",
    "            print(f\"### Number of new generated samples: {len(new_weight_sample)}\")\n",
    "\n",
    "            print(\"### Ending: Generating local weight samples\")\n",
    "            # print(f\"### Tracking compress weight samples: {self._compressed_weight_samples}\")\n",
    "            self._num_compressed_weight_samples += len(new_weight_sample)\n",
    "            return new_weight_sample\n",
    "\n",
    "    def compress_weight_samples(\n",
    "            self,\n",
    "            threshold : float = 0.5,\n",
    "            alpha: float = 0.05\n",
    "    ) -> np.ndarray:\n",
    "        print(\"### Starting: Compressing weight samples\")\n",
    "        num_each_weight_samples = self._num_weight_samples\n",
    "\n",
    "        N = self._model.num_weights\n",
    "        num_each_weight_samples = int(num_each_weight_samples ** (1 / (np.exp(-alpha * N) *N)))\n",
    "        bound = [(1, 0)]\n",
    "        new_weight_sample = self.generate_local_weight_samples(\n",
    "                    bounds=bound,\n",
    "                    num_new_sample=num_each_weight_samples\n",
    "                )\n",
    "\n",
    "        # original_samples = self._weight_samples  # shape: (N, d)\n",
    "\n",
    "        # 첫 샘플링에서 LED가 threshold 이상인 것들만 추출\n",
    "        high_led_samples = self.threshold_local_effective_dimension_samples(\n",
    "            target_weight_sample=new_weight_sample,\n",
    "            threshold=threshold\n",
    "        )\n",
    "        print(f\"### High led results: {high_led_samples.shape}\")\n",
    "\n",
    "        print(f\"### Number of qualified high-LED samples: {len(high_led_samples)}\")\n",
    "\n",
    "        i = 0\n",
    "        # qualified sample 각각에 대해 지역 탐색 루프 수행\n",
    "        for seed_sample in high_led_samples:\n",
    "            # 초기화\n",
    "            seed_sample = np.asarray(seed_sample).flatten()\n",
    "            bound_factor = num_each_weight_samples\n",
    "            num_local_samples = num_each_weight_samples\n",
    "            bound = [(1, 0)]\n",
    "            # bound = self.weight_value_constrainer(target_sample=seed_sample, shrink=bound_factor)\n",
    "\n",
    "            j = 0\n",
    "            while True:\n",
    "                N = self._model.num_weights\n",
    "                num_local_samples = int(num_local_samples ** (1 / (np.exp(-alpha * N) *N)))\n",
    "\n",
    "                # 새 weight sample 생성\n",
    "                new_weight_sample = self.generate_local_weight_samples(\n",
    "                    bounds=bound,\n",
    "                    num_new_sample=num_local_samples\n",
    "                )\n",
    "                # print(f\"### {i}, {j}, num_local_samples: {num_local_samples}, N: {N}\")\n",
    "\n",
    "                # 지역 샘플 내에서 최대 LED sample 하나 선정\n",
    "                max_sample = self.maximum_local_effective_dimension_sample(new_weight_sample)\n",
    "\n",
    "                # shrink factor를 다시 줄여서 탐색 영역 좁히기\n",
    "                bound_factor = bound_factor ** (1 / self._model.num_weights)\n",
    "                bound = self.weight_value_constrainer(target_sample=max_sample, shrink=bound_factor)\n",
    "\n",
    "                if num_local_samples == 1:\n",
    "                    # 마지막 탐색도 실행 후 break\n",
    "                    self.generate_local_weight_samples(bounds=bound, num_new_sample=1)\n",
    "                    break\n",
    "                j+=1\n",
    "            i+=1\n",
    "        print(f\"### Number of compressself._compressed_weight_samplesed samples: {self._num_compressed_weight_samples}, {len(self._compressed_weight_samples)}\")\n",
    "        print(\"### Ending: Compressing weight samples\")\n",
    "                # return self._compressed_weight_samples\n",
    "\n",
    "\n",
    "    def super_calculate_effective_dimension(\n",
    "            self,\n",
    "            dataset_size: Union[List[int], np.ndarray, int],\n",
    "            gamma: Union[List[float], np.ndarray, float] = 1,\n",
    "            threshold: float = 0.5,\n",
    "            alpha: float = 0.05\n",
    "    ) -> np.ndarray:\n",
    "        N = self._model.num_weights\n",
    "        gamma = 1 / (np.exp(-alpha *N) *N)\n",
    "        self.compress_weight_samples(threshold=threshold,alpha=alpha)\n",
    "        self._weight_samples = self.compress_weight_samples\n",
    "        self._num_weight_samples = self._num_compressed_weight_samples\n",
    "        self.calculateEffectiveDimension(dataset_size=dataset_size, gamma=gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e276fabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Starting: Compressing weight samples\n",
      "### Starting: Generating local weight samples\n",
      "### Number of new generated samples: 12\n",
      "### Ending: Generating local weight samples\n",
      "### Starting: Threshold down scaling\n",
      "### Ending: Threshold down scaling\n",
      "### High led results: (1, 4)\n",
      "### Number of qualified high-LED samples: 1\n",
      "### Starting: Generating local weight samples\n",
      "### Number of new generated samples: 1\n",
      "### Ending: Generating local weight samples\n",
      "### Starting: Maximum LED Sample\n",
      "### Ending: Maximum LED Sample\n",
      "### Bounds [(1.0, 0.0), (1.0, np.float64(0.006780046766083125)), (1.0, 0.0), (1.0, 0.0)]\n",
      "### Starting: Generating local weight samples\n",
      "### Number of new generated samples: 1\n",
      "### Ending: Generating local weight samples\n",
      "### Number of compressed samples: 14, 14\n",
      "### Ending: Compressing weight samples\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\[\n",
       "\\begin{array}{cc}\n",
       " & \\gamma=0.27629272951891193 \\\\\n",
       "n=5000.0 & 0.7168 \\\\\n",
       "n=8000.0 & 0.7378 \\\\\n",
       "n=10000.0 & 0.7470 \\\\\n",
       "n=40000.0 & 0.7937 \\\\\n",
       "n=60000.0 & 0.8047 \\\\\n",
       "n=100000.0 & 0.8170 \\\\\n",
       "n=150000.0 & 0.8258 \\\\\n",
       "n=200000.0 & 0.8316 \\\\\n",
       "n=500000.0 & 0.8478 \\\\\n",
       "n=1000000.0 & 0.8582 \\\\\n",
       "\\end{array}\n",
       "\\]"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "number_of_weight_samples = 10000\n",
    "\n",
    "input_samples = algorithm_globals.random.normal(0, 1, size=(30, qnn.num_inputs))\n",
    "weight_samples = algorithm_globals.random.uniform(0, 1, size=(number_of_weight_samples, qnn.num_weights))\n",
    "\n",
    "effective_dimension = SQuAI_EffectiveDimension(\n",
    "    qnn=qnn,\n",
    "    weight_samples=weight_samples,\n",
    "    input_samples=input_samples,\n",
    ")\n",
    "effective_dimension.super_calculate_effective_dimension(\n",
    "    dataset_size=n, threshold = 0.7, alpha=0.025)\n",
    "\n",
    "effective_dimension.display_effective_dim_latex_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcc0455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\[\n",
       "\\begin{array}{cc}\n",
       " & \\gamma=1.0 \\\\\n",
       "n=5000.0 & 1.2318 \\\\\n",
       "n=8000.0 & 1.2546 \\\\\n",
       "n=10000.0 & 1.2661 \\\\\n",
       "n=40000.0 & 1.3442 \\\\\n",
       "n=60000.0 & 1.3680 \\\\\n",
       "n=100000.0 & 1.3984 \\\\\n",
       "n=150000.0 & 1.4229 \\\\\n",
       "n=200000.0 & 1.4407 \\\\\n",
       "n=500000.0 & 1.5005 \\\\\n",
       "n=1000000.0 & 1.5520 \\\\\n",
       "\\end{array}\n",
       "\\]"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "number_of_weight_samples = 100\n",
    "\n",
    "input_samples = algorithm_globals.random.normal(0, 1, size=(30, qnn.num_inputs))\n",
    "weight_samples = algorithm_globals.random.uniform(0, 1, size=(number_of_weight_samples, qnn.num_weights))\n",
    "\n",
    "effective_dimension = SQuAI_EffectiveDimension(\n",
    "    qnn=qnn,\n",
    "    weight_samples=weight_samples,\n",
    "    input_samples=input_samples,\n",
    ")\n",
    "effective_dimension.buildFIM()\n",
    "effective_dimension.calculateEffectiveDimension(dataset_size=n)\n",
    "# effective_dimension.super_calculate_effective_dimension(dataset_size=n, threshold = 0.9, alpha=0.025)\n",
    "effective_dimension.display_effective_dim_latex_table()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
